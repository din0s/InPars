#!/bin/bash

#SBATCH --job-name=QueriesInPars
#SBATCH --partition=gpu
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=18
#SBATCH --mem=120gb
#SBATCH --time=12:00:00
#SBATCH --output=slurm_queries_%A.out

module purge
module load 2022
module load Anaconda3/2022.05
source activate thesis

mkdir -p $TMPDIR/hf_cache && export HF_DATASETS_CACHE=$_

cd $HOME/InPars
mkdir -p synthetic

python -u \
    -m inpars.generate \
    --prompt instruction-arguana \
    --dataset arguana \
    --dataset_source ir_datasets \
    --base_model EleutherAI/gpt-j-6B \
    --output ./synthetic/arguana.jsonl \
    --n_fewshot_examples 1 \
    --no_repeat_ngram 5 \
    --max_new_tokens 256 \
    --max_query_length 512 \
    --max_doc_length 512 \
    --max_generations 10000 \
    --batch_size 4 \
    --yield_results \
    --fp16

